{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9ca4487",
   "metadata": {},
   "outputs": [],
   "source": [
    "from music21 import *\n",
    "import random, glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc2d2c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining function to read MIDI files\n",
    "def read_midi(file):\n",
    "    \n",
    "    print(\"Loading Music File:\",file)\n",
    "    \n",
    "    notes=[]\n",
    "    notes_to_parse = None\n",
    "    \n",
    "    #parsing a midi file\n",
    "    midi = converter.parse(file)\n",
    "  \n",
    "    #grouping based on different instruments\n",
    "    s2 = instrument.partitionByInstrument(midi)\n",
    "\n",
    "    #Looping over all the instruments\n",
    "    for part in s2.parts:\n",
    "    \n",
    "        #select elements of only piano\n",
    "        if 'Piano' in str(part): \n",
    "        \n",
    "            notes_to_parse = part.recurse() \n",
    "      \n",
    "            #finding whether a particular element is note or a chord\n",
    "            for element in notes_to_parse:\n",
    "                \n",
    "                #note\n",
    "                if isinstance(element, note.Note):\n",
    "                    notes.append(str(element.pitch))\n",
    "                \n",
    "                #chord\n",
    "                elif isinstance(element, chord.Chord):\n",
    "                    notes.append('.'.join(str(n) for n in element.normalOrder))\n",
    "\n",
    "    return np.array(notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ad8a4d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Music File: dataset/tschai\\ty_april.mid\n",
      "Loading Music File: dataset/tschai\\ty_august.mid\n",
      "Loading Music File: dataset/tschai\\ty_dezember.mid\n",
      "Loading Music File: dataset/tschai\\ty_februar.mid\n",
      "Loading Music File: dataset/tschai\\ty_januar.mid\n",
      "Loading Music File: dataset/tschai\\ty_juli.mid\n",
      "Loading Music File: dataset/tschai\\ty_juni.mid\n",
      "Loading Music File: dataset/tschai\\ty_maerz.mid\n",
      "Loading Music File: dataset/tschai\\ty_mai.mid\n",
      "Loading Music File: dataset/tschai\\ty_november.mid\n",
      "Loading Music File: dataset/tschai\\ty_oktober.mid\n",
      "Loading Music File: dataset/tschai\\ty_september.mid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\AppData\\Local\\Temp\\ipykernel_7052\\2431627556.py:16: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  notes_array = np.array([read_midi(i) for i in files])\n"
     ]
    }
   ],
   "source": [
    "#for listing down the file names\n",
    "import os\n",
    "\n",
    "#Array Processing\n",
    "import numpy as np\n",
    "\n",
    "#specify the path\n",
    "path=\"dataset\"\n",
    "files = [a for a in glob.glob(\"dataset/*/*\")]\n",
    "files = [a for a in glob.glob(\"dataset/tschai/*\")]\n",
    "\n",
    "#read all the filenames\n",
    "#files=[i for i in os.listdir(path) if i.endswith(\".mid\")]\n",
    "\n",
    "#reading each midi file\n",
    "notes_array = np.array([read_midi(i) for i in files])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e73aedf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "243\n"
     ]
    }
   ],
   "source": [
    "#converting 2D array into 1D array\n",
    "notes_ = [element for note_ in notes_array for element in note_]\n",
    "\n",
    "#No. of unique notes\n",
    "unique_notes = list(set(notes_))\n",
    "print(len(unique_notes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e988013",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([158.,  28.,  14.,  10.,   8.,   6.,   6.,   7.,   2.,   4.]),\n",
       " array([  1. ,  33.7,  66.4,  99.1, 131.8, 164.5, 197.2, 229.9, 262.6,\n",
       "        295.3, 328. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 302,
       "width": 319
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#importing library\n",
    "from collections import Counter\n",
    "\n",
    "#computing frequency of each note\n",
    "freq = dict(Counter(notes_))\n",
    "\n",
    "#library for visualiation\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#consider only the frequencies\n",
    "no=[count for _,count in freq.items()]\n",
    "\n",
    "#set the figure size\n",
    "plt.figure(figsize=(5,5))\n",
    "\n",
    "#plot\n",
    "plt.hist(no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "669c2e0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n"
     ]
    }
   ],
   "source": [
    "#keeping th higher frequncy only. more than 50 for now\n",
    "frequent_notes = [note_ for note_, count in freq.items() if count>=50]\n",
    "print(len(frequent_notes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21f5441d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\AppData\\Local\\Temp\\ipykernel_7052\\2871568428.py:10: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  new_music = np.array(new_music)\n"
     ]
    }
   ],
   "source": [
    "new_music=[]\n",
    "\n",
    "for notes in notes_array:\n",
    "    temp=[]\n",
    "    for note_ in notes:\n",
    "        if note_ in frequent_notes:\n",
    "            temp.append(note_)            \n",
    "    new_music.append(temp)\n",
    "    \n",
    "new_music = np.array(new_music)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c1aa01ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_of_timesteps = 32\n",
    "x = []\n",
    "y = []\n",
    "\n",
    "for note_ in new_music:\n",
    "    for i in range(0, len(note_) - no_of_timesteps, 1):\n",
    "        \n",
    "        #preparing input and output sequences\n",
    "        input_ = note_[i:i + no_of_timesteps]\n",
    "        output = note_[i + no_of_timesteps]\n",
    "        \n",
    "        x.append(input_)\n",
    "        y.append(output)\n",
    "        \n",
    "x=np.array(x)\n",
    "y=np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "22619098",
   "metadata": {},
   "outputs": [],
   "source": [
    "#assigning unique integer to every notes\n",
    "unique_x = list(set(x.ravel()))\n",
    "x_note_to_int = dict((note_, number) for number, note_ in enumerate(unique_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "51eaefd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#preparing input sequences\n",
    "x_seq=[]\n",
    "for i in x:\n",
    "    temp=[]\n",
    "    for j in i:\n",
    "        #assigning unique integer to every note\n",
    "        temp.append(x_note_to_int[j])\n",
    "    x_seq.append(temp)\n",
    "    \n",
    "x_seq = np.array(x_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b14c3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the integer sequences for output data as well\n",
    "\n",
    "unique_y = list(set(y))\n",
    "y_note_to_int = dict((note_, number) for number, note_ in enumerate(unique_y)) \n",
    "y_seq=np.array([y_note_to_int[i] for i in y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c3988fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preserving 80% of the data for training and the rest 20% for the evaluation:\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_tr, x_val, y_tr, y_val = train_test_split(x_seq,y_seq,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "953c954b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm():\n",
    "  model = Sequential()\n",
    "  model.add(LSTM(128,return_sequences=True))\n",
    "  model.add(LSTM(128))\n",
    "  model.add(Dense(256))\n",
    "  model.add(Activation('relu'))\n",
    "  model.add(Dense(n_vocab))\n",
    "  model.add(Activation('softmax'))\n",
    "  model.compile(loss='sparse_categorical_crossentropy', optimizer='adam')\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "02e882a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 32, 100)           6400      \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 32, 64)            19264     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 32, 64)            0         \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 16, 64)           0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 16, 128)           24704     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 16, 128)           0         \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 8, 128)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 8, 256)            98560     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 8, 256)            0         \n",
      "                                                                 \n",
      " max_pooling1d_2 (MaxPooling  (None, 4, 256)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " global_max_pooling1d (Globa  (None, 256)              0         \n",
      " lMaxPooling1D)                                                  \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               65792     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                16448     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 231,168\n",
      "Trainable params: 231,168\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import *\n",
    "from keras.models import *\n",
    "from keras.callbacks import *\n",
    "import keras.backend as K\n",
    "\n",
    "K.clear_session()\n",
    "model = Sequential()\n",
    "    \n",
    "#embedding layer\n",
    "model.add(Embedding(len(unique_x), 100, input_length=32,trainable=True)) \n",
    "\n",
    "model.add(Conv1D(64,3, padding='causal',activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(MaxPool1D(2))\n",
    "    \n",
    "model.add(Conv1D(128,3,activation='relu',dilation_rate=2,padding='causal'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(MaxPool1D(2))\n",
    "\n",
    "model.add(Conv1D(256,3,activation='relu',dilation_rate=4,padding='causal'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(MaxPool1D(2))\n",
    "          \n",
    "#model.add(Conv1D(256,5,activation='relu'))    \n",
    "model.add(GlobalMaxPool1D())\n",
    "    \n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(len(unique_y), activation='softmax'))\n",
    "    \n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1e781404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: h5py in c:\\users\\dell\\anaconda3\\lib\\site-packages (3.8.0)\n",
      "Requirement already satisfied: numpy>=1.14.5 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from h5py) (1.21.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install h5py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "584b7176",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "51366871",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining call back to save the best model during training>\n",
    "mc=ModelCheckpoint('best_model.h5', monitor='val_loss', mode='min', save_best_only=True,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e916b486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "59/59 [==============================] - ETA: 0s - loss: 4.0477\n",
      "Epoch 00001: val_loss improved from inf to 3.99623, saving model to best_model.h5\n",
      "59/59 [==============================] - 4s 53ms/step - loss: 4.0477 - val_loss: 3.9962\n",
      "Epoch 2/50\n",
      "58/59 [============================>.] - ETA: 0s - loss: 3.9070\n",
      "Epoch 00002: val_loss improved from 3.99623 to 3.86979, saving model to best_model.h5\n",
      "59/59 [==============================] - 3s 52ms/step - loss: 3.9064 - val_loss: 3.8698\n",
      "Epoch 3/50\n",
      "58/59 [============================>.] - ETA: 0s - loss: 3.6763\n",
      "Epoch 00003: val_loss improved from 3.86979 to 3.63825, saving model to best_model.h5\n",
      "59/59 [==============================] - 3s 50ms/step - loss: 3.6778 - val_loss: 3.6383\n",
      "Epoch 4/50\n",
      "58/59 [============================>.] - ETA: 0s - loss: 3.5066\n",
      "Epoch 00004: val_loss improved from 3.63825 to 3.55562, saving model to best_model.h5\n",
      "59/59 [==============================] - 3s 52ms/step - loss: 3.5069 - val_loss: 3.5556\n",
      "Epoch 5/50\n",
      "58/59 [============================>.] - ETA: 0s - loss: 3.4096\n",
      "Epoch 00005: val_loss improved from 3.55562 to 3.50082, saving model to best_model.h5\n",
      "59/59 [==============================] - 3s 51ms/step - loss: 3.4072 - val_loss: 3.5008\n",
      "Epoch 6/50\n",
      "58/59 [============================>.] - ETA: 0s - loss: 3.3321\n",
      "Epoch 00006: val_loss improved from 3.50082 to 3.41194, saving model to best_model.h5\n",
      "59/59 [==============================] - 3s 50ms/step - loss: 3.3321 - val_loss: 3.4119\n",
      "Epoch 7/50\n",
      "59/59 [==============================] - ETA: 0s - loss: 3.2455\n",
      "Epoch 00007: val_loss improved from 3.41194 to 3.36289, saving model to best_model.h5\n",
      "59/59 [==============================] - 3s 52ms/step - loss: 3.2455 - val_loss: 3.3629\n",
      "Epoch 8/50\n",
      "59/59 [==============================] - ETA: 0s - loss: 3.1690\n",
      "Epoch 00008: val_loss improved from 3.36289 to 3.30383, saving model to best_model.h5\n",
      "59/59 [==============================] - 3s 50ms/step - loss: 3.1690 - val_loss: 3.3038\n",
      "Epoch 9/50\n",
      "58/59 [============================>.] - ETA: 0s - loss: 3.1028\n",
      "Epoch 00009: val_loss improved from 3.30383 to 3.29895, saving model to best_model.h5\n",
      "59/59 [==============================] - 3s 49ms/step - loss: 3.1026 - val_loss: 3.2989\n",
      "Epoch 10/50\n",
      "58/59 [============================>.] - ETA: 0s - loss: 3.0347\n",
      "Epoch 00010: val_loss improved from 3.29895 to 3.24251, saving model to best_model.h5\n",
      "59/59 [==============================] - 3s 54ms/step - loss: 3.0349 - val_loss: 3.2425\n",
      "Epoch 11/50\n",
      "59/59 [==============================] - ETA: 0s - loss: 2.9776\n",
      "Epoch 00011: val_loss improved from 3.24251 to 3.21018, saving model to best_model.h5\n",
      "59/59 [==============================] - 3s 53ms/step - loss: 2.9776 - val_loss: 3.2102\n",
      "Epoch 12/50\n",
      "59/59 [==============================] - ETA: 0s - loss: 2.9259\n",
      "Epoch 00012: val_loss improved from 3.21018 to 3.14811, saving model to best_model.h5\n",
      "59/59 [==============================] - 3s 49ms/step - loss: 2.9259 - val_loss: 3.1481\n",
      "Epoch 13/50\n",
      "58/59 [============================>.] - ETA: 0s - loss: 2.8610\n",
      "Epoch 00013: val_loss improved from 3.14811 to 3.11662, saving model to best_model.h5\n",
      "59/59 [==============================] - 3s 52ms/step - loss: 2.8622 - val_loss: 3.1166\n",
      "Epoch 14/50\n",
      "58/59 [============================>.] - ETA: 0s - loss: 2.7920\n",
      "Epoch 00014: val_loss improved from 3.11662 to 3.10811, saving model to best_model.h5\n",
      "59/59 [==============================] - 3s 58ms/step - loss: 2.7915 - val_loss: 3.1081\n",
      "Epoch 15/50\n",
      "58/59 [============================>.] - ETA: 0s - loss: 2.7418\n",
      "Epoch 00015: val_loss improved from 3.10811 to 3.06379, saving model to best_model.h5\n",
      "59/59 [==============================] - 4s 61ms/step - loss: 2.7422 - val_loss: 3.0638\n",
      "Epoch 16/50\n",
      "58/59 [============================>.] - ETA: 0s - loss: 2.7001\n",
      "Epoch 00016: val_loss improved from 3.06379 to 3.06050, saving model to best_model.h5\n",
      "59/59 [==============================] - 4s 72ms/step - loss: 2.6977 - val_loss: 3.0605\n",
      "Epoch 17/50\n",
      "58/59 [============================>.] - ETA: 0s - loss: 2.6412\n",
      "Epoch 00017: val_loss improved from 3.06050 to 3.01017, saving model to best_model.h5\n",
      "59/59 [==============================] - 3s 58ms/step - loss: 2.6408 - val_loss: 3.0102\n",
      "Epoch 18/50\n",
      "59/59 [==============================] - ETA: 0s - loss: 2.5916\n",
      "Epoch 00018: val_loss did not improve from 3.01017\n",
      "59/59 [==============================] - 3s 59ms/step - loss: 2.5916 - val_loss: 3.0170\n",
      "Epoch 19/50\n",
      "58/59 [============================>.] - ETA: 0s - loss: 2.5528\n",
      "Epoch 00019: val_loss improved from 3.01017 to 2.98597, saving model to best_model.h5\n",
      "59/59 [==============================] - 4s 64ms/step - loss: 2.5542 - val_loss: 2.9860\n",
      "Epoch 20/50\n",
      "58/59 [============================>.] - ETA: 0s - loss: 2.4942\n",
      "Epoch 00020: val_loss improved from 2.98597 to 2.97625, saving model to best_model.h5\n",
      "59/59 [==============================] - 4s 61ms/step - loss: 2.4956 - val_loss: 2.9763\n",
      "Epoch 21/50\n",
      "59/59 [==============================] - ETA: 0s - loss: 2.4524\n",
      "Epoch 00021: val_loss improved from 2.97625 to 2.95535, saving model to best_model.h5\n",
      "59/59 [==============================] - 4s 64ms/step - loss: 2.4524 - val_loss: 2.9553\n",
      "Epoch 22/50\n",
      "58/59 [============================>.] - ETA: 0s - loss: 2.4108\n",
      "Epoch 00022: val_loss improved from 2.95535 to 2.93803, saving model to best_model.h5\n",
      "59/59 [==============================] - 4s 62ms/step - loss: 2.4106 - val_loss: 2.9380\n",
      "Epoch 23/50\n",
      "59/59 [==============================] - ETA: 0s - loss: 2.3632\n",
      "Epoch 00023: val_loss improved from 2.93803 to 2.92488, saving model to best_model.h5\n",
      "59/59 [==============================] - 4s 63ms/step - loss: 2.3632 - val_loss: 2.9249\n",
      "Epoch 24/50\n",
      "58/59 [============================>.] - ETA: 0s - loss: 2.3230\n",
      "Epoch 00024: val_loss improved from 2.92488 to 2.89070, saving model to best_model.h5\n",
      "59/59 [==============================] - 3s 57ms/step - loss: 2.3225 - val_loss: 2.8907\n",
      "Epoch 25/50\n",
      "58/59 [============================>.] - ETA: 0s - loss: 2.2875\n",
      "Epoch 00025: val_loss did not improve from 2.89070\n",
      "59/59 [==============================] - 3s 55ms/step - loss: 2.2878 - val_loss: 2.8994\n",
      "Epoch 26/50\n",
      "59/59 [==============================] - ETA: 0s - loss: 2.2591\n",
      "Epoch 00026: val_loss improved from 2.89070 to 2.88158, saving model to best_model.h5\n",
      "59/59 [==============================] - 3s 58ms/step - loss: 2.2591 - val_loss: 2.8816\n",
      "Epoch 27/50\n",
      "58/59 [============================>.] - ETA: 0s - loss: 2.1896\n",
      "Epoch 00027: val_loss did not improve from 2.88158\n",
      "59/59 [==============================] - 3s 49ms/step - loss: 2.1911 - val_loss: 2.8870\n",
      "Epoch 28/50\n",
      "58/59 [============================>.] - ETA: 0s - loss: 2.1862\n",
      "Epoch 00028: val_loss did not improve from 2.88158\n",
      "59/59 [==============================] - 3s 52ms/step - loss: 2.1868 - val_loss: 2.8870\n",
      "Epoch 29/50\n",
      "58/59 [============================>.] - ETA: 0s - loss: 2.1335\n",
      "Epoch 00029: val_loss improved from 2.88158 to 2.83447, saving model to best_model.h5\n",
      "59/59 [==============================] - 3s 55ms/step - loss: 2.1357 - val_loss: 2.8345\n",
      "Epoch 30/50\n",
      "58/59 [============================>.] - ETA: 0s - loss: 2.1049\n",
      "Epoch 00030: val_loss did not improve from 2.83447\n",
      "59/59 [==============================] - 3s 55ms/step - loss: 2.1014 - val_loss: 2.8546\n",
      "Epoch 31/50\n",
      "58/59 [============================>.] - ETA: 0s - loss: 2.0527\n",
      "Epoch 00031: val_loss did not improve from 2.83447\n",
      "59/59 [==============================] - 3s 55ms/step - loss: 2.0495 - val_loss: 2.8440\n",
      "Epoch 32/50\n",
      "59/59 [==============================] - ETA: 0s - loss: 2.0311\n",
      "Epoch 00032: val_loss improved from 2.83447 to 2.80230, saving model to best_model.h5\n",
      "59/59 [==============================] - 4s 62ms/step - loss: 2.0311 - val_loss: 2.8023\n",
      "Epoch 33/50\n",
      "58/59 [============================>.] - ETA: 0s - loss: 1.9927\n",
      "Epoch 00033: val_loss did not improve from 2.80230\n",
      "59/59 [==============================] - 3s 52ms/step - loss: 1.9933 - val_loss: 2.8232\n",
      "Epoch 34/50\n",
      "59/59 [==============================] - ETA: 0s - loss: 1.9711\n",
      "Epoch 00034: val_loss did not improve from 2.80230\n",
      "59/59 [==============================] - 3s 55ms/step - loss: 1.9711 - val_loss: 2.8047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/50\n",
      "58/59 [============================>.] - ETA: 0s - loss: 1.9132\n",
      "Epoch 00035: val_loss did not improve from 2.80230\n",
      "59/59 [==============================] - 3s 59ms/step - loss: 1.9159 - val_loss: 2.8093\n",
      "Epoch 36/50\n",
      "58/59 [============================>.] - ETA: 0s - loss: 1.8778\n",
      "Epoch 00036: val_loss improved from 2.80230 to 2.78837, saving model to best_model.h5\n",
      "59/59 [==============================] - 4s 63ms/step - loss: 1.8761 - val_loss: 2.7884\n",
      "Epoch 37/50\n",
      "58/59 [============================>.] - ETA: 0s - loss: 1.8639\n",
      "Epoch 00037: val_loss improved from 2.78837 to 2.76618, saving model to best_model.h5\n",
      "59/59 [==============================] - 4s 65ms/step - loss: 1.8622 - val_loss: 2.7662\n",
      "Epoch 38/50\n",
      "59/59 [==============================] - ETA: 0s - loss: 1.8523\n",
      "Epoch 00038: val_loss did not improve from 2.76618\n",
      "59/59 [==============================] - 4s 66ms/step - loss: 1.8523 - val_loss: 2.7780\n",
      "Epoch 39/50\n",
      "59/59 [==============================] - ETA: 0s - loss: 1.8397\n",
      "Epoch 00039: val_loss improved from 2.76618 to 2.75782, saving model to best_model.h5\n",
      "59/59 [==============================] - 4s 69ms/step - loss: 1.8397 - val_loss: 2.7578\n",
      "Epoch 40/50\n",
      "59/59 [==============================] - ETA: 0s - loss: 1.7835\n",
      "Epoch 00040: val_loss did not improve from 2.75782\n",
      "59/59 [==============================] - 4s 72ms/step - loss: 1.7835 - val_loss: 2.7734\n",
      "Epoch 41/50\n",
      "58/59 [============================>.] - ETA: 0s - loss: 1.7644\n",
      "Epoch 00041: val_loss improved from 2.75782 to 2.74437, saving model to best_model.h5\n",
      "59/59 [==============================] - 5s 79ms/step - loss: 1.7674 - val_loss: 2.7444\n",
      "Epoch 42/50\n",
      "59/59 [==============================] - ETA: 0s - loss: 1.7404\n",
      "Epoch 00042: val_loss improved from 2.74437 to 2.74120, saving model to best_model.h5\n",
      "59/59 [==============================] - 4s 66ms/step - loss: 1.7404 - val_loss: 2.7412\n",
      "Epoch 43/50\n",
      "58/59 [============================>.] - ETA: 0s - loss: 1.7303\n",
      "Epoch 00043: val_loss improved from 2.74120 to 2.71474, saving model to best_model.h5\n",
      "59/59 [==============================] - 4s 59ms/step - loss: 1.7340 - val_loss: 2.7147\n",
      "Epoch 44/50\n",
      "58/59 [============================>.] - ETA: 0s - loss: 1.6824\n",
      "Epoch 00044: val_loss did not improve from 2.71474\n",
      "59/59 [==============================] - 4s 68ms/step - loss: 1.6839 - val_loss: 2.7194\n",
      "Epoch 45/50\n",
      "58/59 [============================>.] - ETA: 0s - loss: 1.6595\n",
      "Epoch 00045: val_loss did not improve from 2.71474\n",
      "59/59 [==============================] - 4s 61ms/step - loss: 1.6611 - val_loss: 2.7268\n",
      "Epoch 46/50\n",
      "59/59 [==============================] - ETA: 0s - loss: 1.6241\n",
      "Epoch 00046: val_loss did not improve from 2.71474\n",
      "59/59 [==============================] - 4s 70ms/step - loss: 1.6241 - val_loss: 2.7241\n",
      "Epoch 47/50\n",
      "58/59 [============================>.] - ETA: 0s - loss: 1.6494\n",
      "Epoch 00047: val_loss did not improve from 2.71474\n",
      "59/59 [==============================] - 4s 63ms/step - loss: 1.6487 - val_loss: 2.7800\n",
      "Epoch 48/50\n",
      "59/59 [==============================] - ETA: 0s - loss: 1.6039\n",
      "Epoch 00048: val_loss did not improve from 2.71474\n",
      "59/59 [==============================] - 4s 62ms/step - loss: 1.6039 - val_loss: 2.7657\n",
      "Epoch 49/50\n",
      "59/59 [==============================] - ETA: 0s - loss: 1.5809\n",
      "Epoch 00049: val_loss did not improve from 2.71474\n",
      "59/59 [==============================] - 4s 60ms/step - loss: 1.5809 - val_loss: 2.7528\n",
      "Epoch 50/50\n",
      "58/59 [============================>.] - ETA: 0s - loss: 1.5605\n",
      "Epoch 00050: val_loss did not improve from 2.71474\n",
      "59/59 [==============================] - 3s 57ms/step - loss: 1.5601 - val_loss: 2.7194\n"
     ]
    }
   ],
   "source": [
    "# actual training starting\n",
    "history = model.fit(np.array(x_tr),np.array(y_tr),batch_size=128,epochs=50, \n",
    "                    validation_data=(np.array(x_val),np.array(y_val)),verbose=1, callbacks=[mc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2865acc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee900b21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "91afdcd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading best model\n",
    "from keras.models import load_model\n",
    "model = load_model('best_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "eb19b326",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([15, 23,  6, 53,  6, 31,  3, 16, 14, 17,  6, 53,  5, 32,  0, 17, 31,\n",
       "        3, 16, 14, 17,  6, 53,  5, 32,  0, 17, 31,  3, 16,  0, 26])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "ind = np.random.randint(0,len(x_val)-1)\n",
    "\n",
    "random_music = x_val[ind]\n",
    "random_music"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1c1a5325",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[38, 53, 55, 53, 36, 36, 36, 17, 0, 17]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "predictions=[]\n",
    "for i in range(10):\n",
    "\n",
    "    random_music = random_music.reshape(1,no_of_timesteps)\n",
    "\n",
    "    prob  = model.predict(random_music)[0]\n",
    "    y_pred= np.argmax(prob,axis=0)\n",
    "    predictions.append(y_pred)\n",
    "\n",
    "    random_music = np.insert(random_music[0],len(random_music[0]),y_pred)\n",
    "    random_music = random_music[1:]\n",
    "    \n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "55d88558",
   "metadata": {},
   "outputs": [],
   "source": [
    "#intergers back to notes\n",
    "x_int_to_note = dict((number, note_) for number, note_ in enumerate(unique_x)) \n",
    "predicted_notes = [x_int_to_note[i] for i in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2c91e35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# notes to midi format:\n",
    "def convert_to_midi(prediction_output):\n",
    "   \n",
    "    offset = 0\n",
    "    output_notes = []\n",
    "\n",
    "    # create note and chord objects based on the values generated by the model\n",
    "    for pattern in prediction_output:\n",
    "        \n",
    "        # pattern is a chord\n",
    "        if ('.' in pattern) or pattern.isdigit():\n",
    "            notes_in_chord = pattern.split('.')\n",
    "            notes = []\n",
    "            for current_note in notes_in_chord:\n",
    "                \n",
    "                cn=int(current_note)\n",
    "                new_note = note.Note(cn)\n",
    "                new_note.storedInstrument = instrument.Piano()\n",
    "                notes.append(new_note)\n",
    "                \n",
    "            new_chord = chord.Chord(notes)\n",
    "            new_chord.offset = offset\n",
    "            output_notes.append(new_chord)\n",
    "            \n",
    "        # pattern is a note\n",
    "        else:\n",
    "            \n",
    "            new_note = note.Note(pattern)\n",
    "            new_note.offset = offset\n",
    "            new_note.storedInstrument = instrument.Piano()\n",
    "            output_notes.append(new_note)\n",
    "\n",
    "        # increase offset each iteration so that notes do not stack\n",
    "        offset += 1\n",
    "    midi_stream = stream.Stream(output_notes)\n",
    "    midi_stream.write('midi', fp='music.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "585379ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "midi_converted = convert_to_midi(predicted_notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fbaf3a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from music21 import midi\n",
    "def play_midi_file(midi_file_name):\n",
    "    mf = midi.MidiFile()\n",
    "\n",
    "    mf.open(midi_file_name) # path='abc.midi'\n",
    "    mf.read()\n",
    "    mf.close()\n",
    "    s = midi.translate.midiFileToStream(mf)\n",
    "    s.show('midi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6bd275da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                <div id=\"midiPlayerDiv100572\"></div>\n",
       "                <link rel=\"stylesheet\" href=\"//cuthbertLab.github.io/music21j/css/m21.css\"\n",
       "                    type=\"text/css\" />\n",
       "                \n",
       "                <script>\n",
       "                require.config({\n",
       "                    paths: {'music21': '//cuthbertLab.github.io/music21j/src/music21'}\n",
       "                });\n",
       "                require(['music21'], function() {\n",
       "                               mp = new music21.miditools.MidiPlayer();\n",
       "                               mp.addPlayer(\"#midiPlayerDiv100572\");\n",
       "                               mp.base64Load(\"data:audio/midi;base64,TVRoZAAAAAYAAQACBABNVHJrAAAAFAD/UQMHoSAA/1gEBAIYCIgA/y8ATVRyawAAAJMA/wMAAOAAQADAAIgAkDFaiACAMQAAkDRaiACANAAAkEdaAJBAWogAgEcAAIBAAACQNFqIAIA0AACQQFoAkEVaiACAQAAAgEUAAJBAWgCQRVqIAIBAAACARQAAkEBaAJBFWogAgEAAAIBFAACQQFqIAIBAAACQRVoAkD1aiACARQAAgD0AAJBAWogAgEAAiAD/LwA=\");\n",
       "                        });\n",
       "                </script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "play_midi_file(\"music.mid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0096634",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
