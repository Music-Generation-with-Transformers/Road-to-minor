{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random, glob\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "music_files = [a for a in glob.glob(\"dataset/*/*\")]\n",
    "print(\"A random song\", random.sample(music_files, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from music21 import midi\n",
    "def play_midi_file(midi_file_name):\n",
    "    mf = midi.MidiFile()\n",
    "\n",
    "    mf.open(midi_file_name) # path='abc.midi'\n",
    "    mf.read()\n",
    "    mf.close()\n",
    "    s = midi.translate.midiFileToStream(mf)\n",
    "    s.show('midi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(music_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from music21 import converter,corpus, chord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tonic_mode_all = []\n",
    "for i, name in enumerate(music_files[:5]):\n",
    "    try:\n",
    "        parsed_score = converter.parse(name)\n",
    "        key_of_one = parsed_score.analyze('key')\n",
    "        tonic_mode_all.append((i, name, key_of_one.tonic.name, key_of_one.mode))\n",
    "    except:\n",
    "        print(f'Error at {i}')\n",
    "        tonic_mode_all.append((i, name, 'NAN', 'NAN'))\n",
    "        continue\n",
    "    print(f'{tonic_mode_all[i]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chords(music_files):\n",
    "    chords = []\n",
    "    for file_no, filename in enumerate(music_files):\n",
    "        try:\n",
    "            chords.append(converter.parse(filename).chordify())\n",
    "            print(f'Happening of {file_no}', \"filename = \", filename)\n",
    "            \n",
    "        except:\n",
    "            print(f'Happening of {file_no}', \"filename = \", filename)\n",
    "            print(\"file failed!!!!!\")\n",
    "            continue\n",
    "        \n",
    "    \n",
    "    return chords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "music_files_25 = music_files[:25]\n",
    "#get_chords(music_files[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "chords_of_all_music = get_chords(music_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compressed chords if all music\n",
    "chords_of_all_music[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from music21 import chord, duration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classifying the music into different modes\n",
    "- firstly, let's code for major mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from music21 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for seeing output from chords and given duration:\n",
    "def get_music_midi_from_chords_and_duration(input_chords):\n",
    "    midi_stream = stream.Stream()\n",
    "\n",
    "    for note_pattern, duration_pattern in input_chords:\n",
    "        notes_in_chord = note_pattern.split('.')\n",
    "        \n",
    "        chord_notes = []\n",
    "        for current_note in notes_in_chord:\n",
    "            new_note = note.Note(current_note)\n",
    "            new_note.duration = duration.Duration(duration_pattern)\n",
    "            new_note.storedInstrument = instrument.Violoncello()\n",
    "            chord_notes.append(new_note)\n",
    "        new_chord = chord.Chord(chord_notes)\n",
    "        \n",
    "        midi_stream.append(new_chord)\n",
    "\n",
    "        new_tempo = tempo.MetronomeMark(number=50)\n",
    "            \n",
    "        midi_stream.append(new_tempo)\n",
    "\n",
    "    midi_stream = midi_stream.chordify()\n",
    "    timestr = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "    new_file = 'output-' + timestr + '.mid'\n",
    "    return midi_stream.write('midi', fp=new_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def round_chord_durations(number):\n",
    "    if(number>1.25):\n",
    "        return 2\n",
    "    if(number>.30):\n",
    "        return 1.25\n",
    "    if(number>.10):\n",
    "        return 0.3\n",
    "    return 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For chord and duration of a single song(music file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chord_and_duration_data(indv_midi_chordified):\n",
    "    chord_duration_data = []\n",
    "    for element in indv_midi_chordified.flat:\n",
    "        if isinstance(element, chord.Chord):\n",
    "            chord_duration = round_chord_durations(element.duration.quarterLength)\n",
    "            chord_name = \".\".join([n.nameWithOctave for n in element.pitches])\n",
    "            chord_duration_data.append((chord_name, chord_duration))\n",
    "\n",
    "    return chord_duration_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "chords_and_duration_data_all_music= []\n",
    "for one_music_chords in chords_of_all_music:\n",
    "   chords_and_duration_data_all_music.append((get_chord_and_duration_data(one_music_chords)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the main data:\n",
    "type(chords_and_duration_data_all_music[0][0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Generating music from our processed chords...\")\n",
    "proccessed_chords_to_midi_sample = get_music_midi_filename_from_chords(chords_and_duration_data_all_music[0][4:50])\n",
    "print(proccessed_chords_to_midi_sample)\n",
    "play_midi_file(proccessed_chords_to_midi_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from Tonic_mode_all, separating major and minor songs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tonic_mode_all[0][0], tonic_mode_all[0][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_major_songs_chords_and_duration = []\n",
    "all_minor_songs_chords_and_duration = []\n",
    "for i in range(len(tonic_mode_all)):\n",
    "    if(tonic_mode_all[i][-1] == 'major'):\n",
    "        try:\n",
    "            all_major_songs_chords_and_duration.append(chords_and_duration_data_all_music[i])\n",
    "        except:\n",
    "            all_major_songs_chords_and_duration.append('NANNNNNN')\n",
    "    else:\n",
    "        try:\n",
    "            all_minor_songs_chords_and_duration.append(chords_and_duration_data_all_music[i])\n",
    "        except:\n",
    "             all_minor_songs_chords_and_duration.append('NANNNNNN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_minor_songs_chords_and_duration), #minor_songs_chords_with_duration, len(minor_songs_chords_with_duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "major_dataset = all_major_songs_chords_and_duration \n",
    "minor_dataset = all_minor_songs_chords_and_duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#just a reference code\n",
    "#major_dataset\n",
    "#y=np.array(major_dataset)\n",
    "#unique = set(major_dataset_all)\n",
    "#unique2 = set(minor_dataset_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chords_and_duration_data_all_music"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_dataset = chords_and_duration_data_all_music"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Data preparation stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_of_timesteps = 32\n",
    "x = []\n",
    "y = []\n",
    "## CD stands for chord and duration.\n",
    "\n",
    "for each_music_with_CD in main_dataset:\n",
    "    for each_CD in range(0, len(each_music_with_CD) - no_of_timesteps,  1):\n",
    "        \n",
    "        ## preparing input and output sequences:\n",
    "        input_ = each_music_with_CD[i:i + no_of_timesteps]\n",
    "        output = each_music_with_CD[i + no_of_timesteps]\n",
    "        \n",
    "        for i in range(len(input_)):\n",
    "            input_[i]= \"@\".join(map(str,input_[i]))\n",
    "            \n",
    "        output = \"@\".join(map(str,output))\n",
    "        \n",
    "        x.append(input_)\n",
    "        y.append(output)\n",
    "        \n",
    "x=np.array(x)\n",
    "y=np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assigning unique integer to every chords_and_duration\n",
    "\n",
    "unique_x_CD = list(set(x.ravel()))\n",
    "unique_x_CD_to_int = dict((chord_and_duration, number) for number, chord_and_duration in enumerate(unique_x_CD))\n",
    "unique_x_CD_to_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preparing input sequences::\n",
    "\n",
    "x_seq=[]\n",
    "for each_row in x:\n",
    "    temp=[]\n",
    "    for each_piece in each_row:\n",
    "        #assigning unique integer to every note\n",
    "        temp.append(unique_x_CD_to_int[each_piece])\n",
    "    x_seq.append(temp)\n",
    "    \n",
    "x_seq = np.array(x_seq)\n",
    "x_seq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# preparing th output sequences as well::\n",
    "\n",
    "unique_y_CD = list(set(y))\n",
    "unique_y_CD_to_int = dict((chord_and_duration, number) for number, chord_and_duration in enumerate(unique_y_CD)) \n",
    "unique_y_CD_to_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_seq=np.array([unique_y_CD_to_int[i] for i in y])\n",
    "y_seq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preserving 80% of the data for training and the rest 20% for the evaluation:\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_seq,y_seq,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model building phase:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.experimental.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import *\n",
    "from keras.models import *\n",
    "from keras.callbacks import *\n",
    "import keras.backend as K\n",
    "\n",
    "K.clear_session()\n",
    "model = Sequential()\n",
    "    \n",
    "#embedding layer\n",
    "model.add(Embedding(len(unique_x_CD), 100, input_length=32,trainable=True)) \n",
    "\n",
    "model.add(Conv1D(64,3, padding='causal',activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(MaxPool1D(2))\n",
    "    \n",
    "model.add(Conv1D(128,3,activation='relu',dilation_rate=2,padding='causal'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(MaxPool1D(2))\n",
    "\n",
    "model.add(Conv1D(256,3,activation='relu',dilation_rate=4,padding='causal'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(MaxPool1D(2))\n",
    "          \n",
    "#model.add(Conv1D(256,5,activation='relu'))    \n",
    "model.add(GlobalMaxPool1D())\n",
    "    \n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(len(unique_y_CD), activation='softmax'))\n",
    "    \n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm():\n",
    "    K.clear_session()\n",
    "    model = Sequential()\n",
    "    #embedding layer\n",
    "    model.add(Embedding(len(unique_x_CD), 100, input_length=32,trainable=True)) \n",
    "    model.add(LSTM(128,return_sequences=True))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(128))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(256))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Dense(len(unique_y_CD), activation='softmax'))\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lstm()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining call back to save the best model during training>\n",
    "mc=ModelCheckpoint('best_model.h5', monitor='val_loss', mode='min', save_best_only=True,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#actual training\n",
    "history = model.fit(np.array(x_train),np.array(y_train),batch_size=128,epochs=10, \n",
    "                   validation_data=(np.array(x_val),np.array(y_val)),verbose=1, callbacks=[mc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading best model (Previously trained modle)\n",
    "from keras.models import load_model\n",
    "model = load_model('best_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "ind = np.random.randint(0,len(x_val)-1)\n",
    "random_music = x_val[ind]\n",
    "random_music"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=[]\n",
    "for i in range(10):\n",
    "\n",
    "    random_music = random_music.reshape(1,no_of_timesteps)\n",
    "    print(\"random music = \", random_music)\n",
    "    \n",
    "\n",
    "    prob  = model.predict(random_music)[0]\n",
    "    y_pred= np.argmax(prob,axis=0)\n",
    "    predictions.append(y_pred)\n",
    "\n",
    "    random_music = np.insert(random_music[0],len(random_music[0]),y_pred)\n",
    "    random_music = random_music[1:]\n",
    "    \n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#intergers back to notes\n",
    "unique_x_int_to_CD = dict((number, note_) for number, note_ in enumerate(unique_x_CD)) \n",
    "unique_x_int_to_CD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_CD = [unique_x_int_to_CD[i] for i in predictions]\n",
    "predicted_CD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_CD_split = []\n",
    "for each_outcome in predicted_CD:\n",
    "    temp_list = []\n",
    "    temp_list = each_outcome.split(\"@\")\n",
    "    temp_list[1] =float(temp_list[1])\n",
    "    predicted_CD_split.append(tuple(temp_list))\n",
    "    \n",
    "\n",
    "predicted_CD_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Generating music from our processed chords...\")\n",
    "proccessed_chords_to_midi_sample = get_music_midi_from_chords_and_duration(predicted_CD_split)\n",
    "print(proccessed_chords_to_midi_sample)\n",
    "play_midi_file(proccessed_chords_to_midi_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "a50afa644c776f7a2a60a52e60e30bd38a1de8f1520052de409d0e9c4f2415b8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
